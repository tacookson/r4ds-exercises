---
title: "18-353"
author: "Alex Cookson"
date: "18/05/2020"
output: html_document
---

### Question 1

One downside of the linear model is that it is sensitive to unusual values because the distance incorporates a squared term. Fit a linear model to the following simulated data, and visualize the results. Rerun a few times to generate different simlated datasets. What do you notice about the model?

```{r q1, eval = FALSE}
sim1a <- tibble(
  x = rep(1:10, each = 3),
  y = x * 1.5 + 6 + rt(length(x), df = 2)
)
```


### Question 2

One way to make linear models more robust is to use a different distance measure. For example, instead of root-mean-squared distance, you could use mean-absolute distance:

```{r q2, eval = FALSE}
measure_distance <- function(mod, data) {
  diff <- data$y - make_prediction(mod, data)
  mean(abs(diff))
}
```

Use `optim()` to fit this model to the previous simulated data and compare it to the linear model.


### Question 3

One challenge with performing numerical optimization is that it's only guaranteed to find one local optima. What's the problem with optimizing a three-parameter model like this?

```{r q3, eval = FALSE}
model1 <- function(a, data) {
  a[1] + data$x * a[2] + a[3]
}
```

